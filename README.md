# About
Ever since I picked up computer vision, all I ever wanted to do in my daily routine is code code and code.  I'm currently self-teaching myself Deep Learning and Machine Learning and I'm intrigued by the large potential it has in every occupation.  Inspired by [Adrian Coyler](https://blog.acolyer.org/about/) and [Patrick Lui](https://github.com/patrick-llgc/Learning-Deep-Learning), I brought myself to read papers to keep myself up to date on the development of AI.  And just like Coyler and Lui, I will summarize every paper I read so that not only I have an understanding of the paper, but so that you can understand the topic without in depth reading.  I would love to share my paper notes to those who are curious, but need an overview of the core concepts.  With all said, if you are a researcher, practioner, or undergrad student, I hope you can take something away from my exploration to AI.

# Getting Started
I recommend reading the most popular neural network architectures to gain an understanding of it's impact in AI. <br>
* [Alex Net](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks) [[notes]](https://github.com/Nathan-Bernardo/Learning-Deep-Learning/blob/master/Notes/CNN_alexnet.md) <br>
* [ZF Net](https://arxiv.org/pdf/1311.2901v3.pdf) [[notes]](https://github.com/Nathan-Bernardo/Learning-Deep-Learning/blob/master/Notes/CNN_znet.md) <br>
* [VGG16](https://arxiv.org/abs/1409.1556) [[notes]](https://github.com/Nathan-Bernardo/Learning-Deep-Learning/blob/master/Notes/CNN_VGG.md) <br>
* [GoogleLetNet](https://arxiv.org/abs/1409.4842) [[notes]](https://github.com/Nathan-Bernardo/Learning-Deep-Learning/blob/master/Notes/CNN_googleLeNet.md) <br>
* [Inception-v2](https://arxiv.org/abs/1502.03167) <br>
* [Inception-v3](https://arxiv.org/abs/1512.00567) <br>
* [Inception-ResNet](https://arxiv.org/abs/1602.07261) <br>
* [Microsoft ResNet](https://arxiv.org/pdf/1512.03385v1.pdf) <br>
* [R-CNN](https://arxiv.org/pdf/1311.2524v5.pdf) <br>
* [Fast R-CNN](https://arxiv.org/pdf/1504.08083.pdf) <br>
* [Faster R-CNN](https://arxiv.org/pdf/1506.01497v3.pdf) <br>
* [Xception](https://arxiv.org/pdf/1610.02357.pdf) <br>
* [Generative Adversial Networks](https://arxiv.org/pdf/1406.2661v1.pdf) <br>
* [Generating Image Description](https://arxiv.org/pdf/1412.2306v2.pdf) <br>
* [Spatial Transformer Networks](https://arxiv.org/pdf/1506.02025.pdf) <br>

## Methods
I believe that people who are just getting started with deep learning should understand the essential techniques in manipulating data for optimal performance.
* [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) 

# Paper Notes
## 2020-02





