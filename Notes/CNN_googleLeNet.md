# Going Deeper with Convolution
*February 2020*

**Overall Impression** <br>
The motivation of the Inception architecture is to prevent the large set of parameters that exist in traditional convoluton neural networks, but have a high-end performance than the convential architectures, like Khrizskey. The Inception model allows for an increase in depth and width.  

**Key Ideas** <br>
* A straightforward approach of improving the performance is increasing the depth and width, but doing would make the model more prone to overfitting and any uniform increase in the number of filters (in the case of 2 chained convolutional layers) results in a quadratic increase of computation.
* 1x1 

**Technical Details** <br>
![GoogeLeNet](https://programmer.help/images/blog/c6713da92ebca30dcdd6f59e52cacf95.jpg)

**Further Reading** <br>
